import OpenAI from 'openai';

// Rate limiting configuration
interface RateLimitConfig {
  maxRequests: number;
  windowMs: number;
  requests: number[];
}

class OpenAIService {
  private client: OpenAI | null = null;
  private rateLimit: RateLimitConfig;
  private readonly maxRetries = 3;
  private readonly retryDelay = 1000; // 1 second

  constructor() {
    // Initialize rate limiting (10 requests per minute)
    this.rateLimit = {
      maxRequests: 10,
      windowMs: 60000, // 1 minute
      requests: []
    };

    this.initializeClient();
  }

  private initializeClient() {
    try {
      // Validate environment variables
      const apiKey = import.meta.env.VITE_OPENAI_API_KEY;
      
      if (!apiKey || apiKey === 'your_openai_api_key_here' || apiKey === 'your_openai_api_key') {
        console.warn('OpenAI API key is not configured properly');
        return;
      }

      // Get organization ID if provided and not empty
      const orgId = import.meta.env.VITE_OPENAI_ORG_ID;
      const organizationId = orgId && orgId.trim() !== '' && orgId !== 'YOUR_ORG_ID' ? orgId : undefined;

      // Initialize OpenAI client
      this.client = new OpenAI({
        apiKey: apiKey,
        organization: organizationId,
        dangerouslyAllowBrowser: true // Note: In production, API calls should go through your backend
      });

      console.log('‚úÖ OpenAI client initialized successfully');
    } catch (error) {
      console.error('‚ùå Failed to initialize OpenAI client:', error);
      this.client = null;
    }
  }

  private checkRateLimit(): boolean {
    const now = Date.now();
    const windowStart = now - this.rateLimit.windowMs;
    
    // Remove old requests outside the window
    this.rateLimit.requests = this.rateLimit.requests.filter(
      timestamp => timestamp > windowStart
    );

    // Check if we're within the limit
    if (this.rateLimit.requests.length >= this.rateLimit.maxRequests) {
      return false;
    }

    // Add current request
    this.rateLimit.requests.push(now);
    return true;
  }

  private async delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  private validateResponse(response: unknown): boolean {
    const res = response as { choices?: { message?: { content?: string } }[] };
    return Boolean(res?.choices?.[0]?.message?.content);
  }

  private sanitizeInput(input: string): string {
    // Remove potentially harmful content
    return input
      .replace(/<script\b[^<]*(?:(?!<\/script>)<[^<]*)*<\/script>/gi, '')
      .replace(/javascript:/gi, '')
      .replace(/on\w+\s*=/gi, '')
      .trim()
      .substring(0, 4000); // Limit input length
  }

  private createSystemPrompt(): string {
    return `–í—ã - AI-–ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è —è–∑—ã–∫–∞ —ç—Å–ø–µ—Ä–∞–Ω—Ç–æ. –í–∞—à–∞ –∑–∞–¥–∞—á–∞:

1. –ü–æ–º–æ–≥–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º –∏–∑—É—á–∞—Ç—å —ç—Å–ø–µ—Ä–∞–Ω—Ç–æ
2. –û—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ –≥—Ä–∞–º–º–∞—Ç–∏–∫–µ, —Å–ª–æ–≤–∞—Ä–µ –∏ –∫—É–ª—å—Ç—É—Ä–µ —ç—Å–ø–µ—Ä–∞–Ω—Ç–æ
3. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—Ç—å –ø—Ä–∏–º–µ—Ä—ã –∏ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è
4. –ë—ã—Ç—å —Ç–µ—Ä–ø–µ–ª–∏–≤—ã–º –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–º —É—á–∏—Ç–µ–ª–µ–º
5. –û—Ç–≤–µ—á–∞—Ç—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –Ω–æ –≤–∫–ª—é—á–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã –Ω–∞ —ç—Å–ø–µ—Ä–∞–Ω—Ç–æ

–ü—Ä–∞–≤–∏–ª–∞:
- –í—Å–µ–≥–¥–∞ –æ—Ç–≤–µ—á–∞–π—Ç–µ –¥—Ä—É–∂–µ–ª—é–±–Ω–æ –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ
- –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–π—Ç–µ —Ç–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± —ç—Å–ø–µ—Ä–∞–Ω—Ç–æ
- –í–∫–ª—é—á–∞–π—Ç–µ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã
- –ü–æ–æ—â—Ä—è–π—Ç–µ –∏–∑—É—á–µ–Ω–∏–µ —è–∑—ã–∫–∞
- –ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—Ç–µ –æ—Ç–≤–µ—Ç, —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏—Ç–µ –æ–± —ç—Ç–æ–º

–û—Ç–≤–µ—á–∞–π—Ç–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
{
  "response": "–≤–∞—à –æ—Ç–≤–µ—Ç –∑–¥–µ—Å—å",
  "examples": ["–ø—Ä–∏–º–µ—Ä 1", "–ø—Ä–∏–º–µ—Ä 2"],
  "tips": ["—Å–æ–≤–µ—Ç 1", "—Å–æ–≤–µ—Ç 2"],
  "difficulty": "beginner|intermediate|advanced"
}`;
  }

  async sendMessage(
    message: string,
    conversationHistory: Array<{ role: 'user' | 'assistant'; content: string }> = []
  ): Promise<{
    response: string;
    examples?: string[];
    tips?: string[];
    difficulty?: string;
    usage?: {
      prompt_tokens: number;
      completion_tokens: number;
      total_tokens: number;
    };
  }> {
    // Check if client is initialized
    if (!this.client) {
      throw new Error('OpenAI API –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é API –∫–ª—é—á–∞.');
    }

    // Check rate limiting
    if (!this.checkRateLimit()) {
      throw new Error('–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —á–µ—Ä–µ–∑ –º–∏–Ω—É—Ç—É.');
    }

    // Sanitize input
    const sanitizedMessage = this.sanitizeInput(message);
    if (!sanitizedMessage) {
      throw new Error('–°–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º');
    }

    // Prepare messages
    const messages: OpenAI.Chat.Completions.ChatCompletionMessageParam[] = [
      { role: 'system', content: this.createSystemPrompt() },
      ...conversationHistory.map(msg => ({
        role: msg.role as 'user' | 'assistant',
        content: msg.content
      })),
      { role: 'user', content: sanitizedMessage }
    ];

    // Retry logic
    for (let attempt = 1; attempt <= this.maxRetries; attempt++) {
      try {
        console.log(`ü§ñ Sending request to OpenAI (attempt ${attempt}/${this.maxRetries})`);
        
        const completion = await this.client.chat.completions.create({
          model: import.meta.env.VITE_OPENAI_MODEL || 'gpt-3.5-turbo',
          messages,
          max_tokens: parseInt(import.meta.env.VITE_OPENAI_MAX_TOKENS || '500'),
          temperature: parseFloat(import.meta.env.VITE_OPENAI_TEMPERATURE || '0.7'),
          response_format: { type: 'json_object' },
          user: `esperanto-learner-${Date.now()}` // Unique user identifier
        });

        console.log('‚úÖ Received response from OpenAI');

        // Validate response
        if (!this.validateResponse(completion)) {
          throw new Error('–ü–æ–ª—É—á–µ–Ω –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç OpenAI');
        }

        const responseContent = completion.choices[0].message.content;
        
        try {
          // Parse JSON response
          const parsedResponse = JSON.parse(responseContent || '{}');
          
          return {
            response: parsedResponse.response || '–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç.',
            examples: parsedResponse.examples || [],
            tips: parsedResponse.tips || [],
            difficulty: parsedResponse.difficulty || 'beginner',
            usage: completion.usage ? {
              prompt_tokens: completion.usage.prompt_tokens,
              completion_tokens: completion.usage.completion_tokens,
              total_tokens: completion.usage.total_tokens
            } : undefined
          };
        } catch (parseError) {
          console.warn('‚ö†Ô∏è Failed to parse JSON response, using fallback');
          // Fallback if JSON parsing fails
          return {
            response: responseContent || '–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç.',
            examples: [],
            tips: [],
            difficulty: 'beginner'
          };
        }

      } catch (error: unknown) {
        console.error(`‚ùå OpenAI API attempt ${attempt} failed:`, error);

        // Handle specific error types
        if ((error as { status?: number }).status === 429) {
          // Check if it's a quota exceeded error vs rate limit
          const errorMessage = (error as { message?: string }).message || '';
          if (errorMessage.includes('quota') || errorMessage.includes('billing')) {
            throw new Error('–ü—Ä–µ–≤—ã—à–µ–Ω–∞ –∫–≤–æ—Ç–∞ OpenAI API. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–ª–∞–Ω –ø–æ–¥–ø–∏—Å–∫–∏ –∏ –±–∏–ª–ª–∏–Ω–≥ –Ω–∞ platform.openai.com');
          } else {
            if (attempt < this.maxRetries) {
              console.log(`‚è≥ Rate limited, waiting ${this.retryDelay * attempt}ms before retry`);
              await this.delay(this.retryDelay * attempt);
              continue;
            }
            throw new Error('–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ API. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç.');
          }
        }

        if (error.status === 401) {
          throw new Error('–û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ API. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å API –∫–ª—é—á–∞ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö.');
        }

        if (error.status === 403) {
          throw new Error('–î–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∞ API –∫–ª—é—á–∞ –∏–ª–∏ –∞–∫—Ç–∏–≤–∏—Ä—É–π—Ç–µ –±–∏–ª–ª–∏–Ω–≥.');
        }

        if (error.status >= 500) {
          if (attempt < this.maxRetries) {
            console.log(`üîÑ Server error, retrying in ${this.retryDelay * attempt}ms`);
            await this.delay(this.retryDelay * attempt);
            continue;
          }
          throw new Error('–û—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ OpenAI. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.');
        }

        // Network errors
        if (error.code === 'NETWORK_ERROR' || error.message.includes('fetch')) {
          if (attempt < this.maxRetries) {
            console.log(`üåê Network error, retrying in ${this.retryDelay * attempt}ms`);
            await this.delay(this.retryDelay * attempt);
            continue;
          }
          throw new Error('–û—à–∏–±–∫–∞ —Å–µ—Ç–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç—É.');
        }

        // Final attempt failed
        if (attempt === this.maxRetries) {
          throw new Error(
            error.message || '–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ AI'
          );
        }
      }
    }

    throw new Error('–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –ø–æ—Å–ª–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ–ø—ã—Ç–æ–∫');
  }

  // Get current rate limit status
  getRateLimitStatus(): {
    remaining: number;
    resetTime: number;
  } {
    const now = Date.now();
    const windowStart = now - this.rateLimit.windowMs;
    
    // Clean old requests
    this.rateLimit.requests = this.rateLimit.requests.filter(
      timestamp => timestamp > windowStart
    );

    const remaining = Math.max(0, this.rateLimit.maxRequests - this.rateLimit.requests.length);
    const oldestRequest = this.rateLimit.requests[0];
    const resetTime = oldestRequest ? oldestRequest + this.rateLimit.windowMs : now;

    return {
      remaining,
      resetTime
    };
  }

  // Check if service is properly configured
  isConfigured(): boolean {
    const apiKey = import.meta.env.VITE_OPENAI_API_KEY;
    return !!(this.client && apiKey && apiKey !== 'your_openai_api_key_here' && apiKey !== 'your_openai_api_key');
  }

  // Test connection with lightweight request
  async testConnection(): Promise<boolean> {
    if (!this.isConfigured()) {
      return false;
    }

    try {
      // Use a minimal test request to avoid quota issues
      const response = await this.client!.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [{ role: 'user', content: 'Hi' }],
        max_tokens: 5,
        temperature: 0
      });

      return this.validateResponse(response);
    } catch (error: unknown) {
      console.error('OpenAI connection test failed:', error);
      
      // Don't throw quota errors during connection test
      if (
        (error as { status?: number; message?: string }).status === 429 &&
        ((error as { message?: string }).message?.includes('quota') ||
          (error as { message?: string }).message?.includes('billing'))
      ) {
        console.warn('Connection test skipped due to quota limits');
        return false;
      }
      
      return false;
    }
  }
}

// Export singleton instance
export const openAIService = new OpenAIService();
